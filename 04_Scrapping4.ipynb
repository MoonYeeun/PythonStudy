{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lxml 사용 기초 스크래핑\n",
    "- 네이버 메인의 신문사 url 갖고 옴 => xpath 사용\n",
    "- session을 사용하면 서버에서 일정 시간동안 연결된 정보를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring, tostring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news_list_page(response):\n",
    "    #URL 딕셔너리 선언\n",
    "    urls = {}\n",
    "    #태그 정보 문자열 저장\n",
    "    root = fromstring(response.content)\n",
    "    \n",
    "    #문서 내 경로 절대 경로 변환\n",
    "    root.make_links_absolute(response.url)\n",
    "    \n",
    "    for a in root.xpath('//ul[@class=\"api_list\"]/li[@class=\"api_item\"]/a[@class=\"api_link\"]'):\n",
    "        #신문사, 링크 추출 함수\n",
    "        name, url = extract_contents(a)\n",
    "        #딕셔너리 삽입\n",
    "        urls[name] = url\n",
    "    return urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contents(dom):\n",
    "    #링크 주소\n",
    "    link = dom.get('href')\n",
    "    \n",
    "    #신문사 명\n",
    "    #dom.xpath()는 리스트로 반환\n",
    "    name = dom.xpath('./img')[0].get('alt')\n",
    "    return name, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동아일보 http://newsstand.naver.com/?list=ct1&pcode=020\n",
      "한국일보 http://newsstand.naver.com/?list=ct1&pcode=038\n",
      "중앙데일리 http://newsstand.naver.com/?list=ct1&pcode=330\n",
      "세계일보 http://newsstand.naver.com/?list=ct1&pcode=022\n",
      "OSEN http://newsstand.naver.com/?list=ct1&pcode=109\n",
      "프레시안 http://newsstand.naver.com/?list=ct1&pcode=002\n",
      "헤럴드경제 http://newsstand.naver.com/?list=ct1&pcode=016\n",
      "중앙일보 http://newsstand.naver.com/?list=ct1&pcode=025\n",
      "스포츠조선 http://newsstand.naver.com/?list=ct1&pcode=076\n",
      "일간스포츠 http://newsstand.naver.com/?list=ct1&pcode=241\n",
      "조선일보 http://newsstand.naver.com/?list=ct1&pcode=023\n",
      "한겨레 http://newsstand.naver.com/?list=ct1&pcode=028\n",
      "사이언스타임즈 http://newsstand.naver.com/?list=ct7&pcode=355\n",
      "스포츠월드 http://newsstand.naver.com/?list=ct6&pcode=396\n",
      "MONEY http://newsstand.naver.com/?list=ct7&pcode=806\n",
      "CNN http://newsstand.naver.com/?list=ct3&pcode=933\n",
      "조세일보 http://newsstand.naver.com/?list=ct2&pcode=123\n",
      "채널예스 http://newsstand.naver.com/?list=ct7&pcode=361\n"
     ]
    }
   ],
   "source": [
    "# 메인함수\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "# 스크랩핑 대상 URL\n",
    "response = session.get('http://www.naver.com/')\n",
    "\n",
    "# 신문사 정보 딕셔너리 획득\n",
    "urls = scrape_news_list_page(response)\n",
    "\n",
    "# 결과 출력\n",
    "for name, url in urls.items():\n",
    "    print(name, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
